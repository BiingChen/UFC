{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Random Forest Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../02_Data/02_Processed_Data/X_train.pkl', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "    \n",
    "with open('../../02_Data/02_Processed_Data/y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)    \n",
    "\n",
    "with open('../../02_Data/02_Processed_Data/X_test.pkl', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "    \n",
    "with open('../../02_Data/02_Processed_Data/y_test.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Select 100 Best and PCA datasets for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../02_Data/02_Processed_Data/X_train_100b.pkl', 'rb') as f:\n",
    "    X_train_100b = pickle.load(f)\n",
    "    \n",
    "with open('../../02_Data/02_Processed_Data/X_test_100b.pkl', 'rb') as f:\n",
    "    X_test_100b = pickle.load(f)\n",
    "    \n",
    "with open('../../02_Data/02_Processed_Data/X_train_100b_pca.pkl', 'rb') as f:\n",
    "    X_train_100b_pca = pickle.load(f)\n",
    "    \n",
    "with open('../../02_Data/02_Processed_Data/X_test_100b_pca.pkl', 'rb') as f:\n",
    "    X_test_100b_pca = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9818786982248521\n",
      "Test: 0.5764705882352941\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "print('Train:', rf.score(X_train,y_train))\n",
    "print('Test:',rf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The untuned random forest classifier does a lot better, at least beating the baseline (50/50). However, the model is significantly overfit with the train being 0.98 and test only coming in at 0.57. This is not surprising because not setting a max depth allows the trees to grow as long as it needs to almost perfectly classify the training data, causing significant overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with Initial Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6834319526627219\n",
      "Test: 0.596078431372549\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=3, min_samples_split=2, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "print('Train:', rf.score(X_train,y_train))\n",
    "print('Test:',rf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating the max depth to 3, setting min samples and increasing the estimators helped to reduce the overfitting by 0.30 and increase the test score, but the model is still quite overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest using Select K Best 100 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9837278106508875\n",
      "Test: 0.5764705882352941\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_100b, y_train)\n",
    "print('Train:', rf.score(X_train_100b,y_train))\n",
    "print('Test:',rf.score(X_test_100b,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing feature selection did not help reduce overfitting and made no difference in the score.  This is unsurprising since the randomforest model was already picking the best features to split on when providing the entire feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6464497041420119\n",
      "Test: 0.6078431372549019\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=3, min_samples_split=2, random_state=42)\n",
    "rf.fit(X_train_100b, y_train)\n",
    "print('Train:', rf.score(X_train_100b,y_train))\n",
    "print('Test:',rf.score(X_test_100b,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some light tuning and feature selection, the model is not as overfit anymore and is also up to 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the splits done for the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f2_head_significant_strikes_landed_diff_avg</th>\n",
       "      <td>0.031720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_head_significant_strikes_percent_avg_diff</th>\n",
       "      <td>0.030295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_head_significant_strikes_landed_avg_diff</th>\n",
       "      <td>0.029473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_significant_strikes_landed_diff_avg</th>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_f2_clinch_head_strikes_percent_avg</th>\n",
       "      <td>0.024601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_significant_strikes_attempts_diff_avg</th>\n",
       "      <td>0.023133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_head_significant_strikes_landed_diff_avg</th>\n",
       "      <td>0.023019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_significant_strikes_landed_diff_avg</th>\n",
       "      <td>0.022822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_distance_head_strikes_landed_avg_diff</th>\n",
       "      <td>0.021123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_head_significant_strikes_attempts_diff_avg</th>\n",
       "      <td>0.020115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "f2_head_significant_strikes_landed_diff_avg    0.031720\n",
       "f2_head_significant_strikes_percent_avg_diff   0.030295\n",
       "f1_head_significant_strikes_landed_avg_diff    0.029473\n",
       "f1_significant_strikes_landed_diff_avg         0.028200\n",
       "f1_f2_clinch_head_strikes_percent_avg          0.024601\n",
       "f1_significant_strikes_attempts_diff_avg       0.023133\n",
       "f1_head_significant_strikes_landed_diff_avg    0.023019\n",
       "f2_significant_strikes_landed_diff_avg         0.022822\n",
       "f1_distance_head_strikes_landed_avg_diff       0.021123\n",
       "f2_head_significant_strikes_attempts_diff_avg  0.020115"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rf.feature_importances_, index=X_train_100b.columns).sort_values(0, ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns \n",
    "# diff -> differential\n",
    "# Try to take denominator out\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.5673076923076923\n",
      "Best Parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Test: 0.6078431372549019\n",
      "CPU times: user 3min 33s, sys: 375 ms, total: 3min 34s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [1000],\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "gs = GridSearchCV(rf, param_grid=rf_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best Score:', gs.best_score_)\n",
    "print('Best Parameters:', gs.best_params_)\n",
    "print('Test:',gs.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search performed about as good as the initial tuning with a score of 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest using Select K Best 100 parameters and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6275887573964497\n",
      "Test: 0.5490196078431373\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=3, min_samples_split=2, random_state=42)\n",
    "rf.fit(X_train_100b_pca, y_train)\n",
    "print('Train:', rf.score(X_train_100b_pca,y_train))\n",
    "print('Test:',rf.score(X_test_100b_pca,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.5558431952662722\n",
      "Best Parameters: {'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Train: 0.6275887573964497\n",
      "Test: 0.5490196078431373\n",
      "CPU times: user 28.3 s, sys: 40.5 ms, total: 28.4 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [1000],\n",
    "    'max_depth': [3, 5, 7,],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "gs = GridSearchCV(rf, param_grid=rf_params)\n",
    "gs.fit(X_train_100b_pca, y_train)\n",
    "print('Best Score:', gs.best_score_)\n",
    "print('Best Parameters:', gs.best_params_)\n",
    "print('Train:',gs.score(X_train_100b_pca,y_train))\n",
    "print('Test:',gs.score(X_test_100b_pca,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like random forest does not perform nearly as well on data that has been through PCA.  I believe this is probably because the splits that are being made are not distinct to specific metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying some random models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb_params = {\n",
    "    'n_estimators': [500, 1000],\n",
    "    'learning_rate': [0.05, 0.1, 0.3],\n",
    "    'max_depth': [3,5]\n",
    "}\n",
    "gb_gs = GridSearchCV(gb, param_grid=gb_params, verbose=2, n_jobs=3 )\n",
    "gb_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.5906065088757396\n",
      "Test: 0.5666666666666667\n",
      "CPU times: user 1.52 s, sys: 3.55 ms, total: 1.52 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gb = GradientBoostingClassifier(n_estimators = 500, learning_rate = 0.001, max_depth= 3, min_samples_leaf=4,\n",
    "                                min_samples_split=4, random_state=42)\n",
    "gb.fit(X_train_100b_pca, y_train)\n",
    "print('Train:', gb.score(X_train_100b_pca,y_train))\n",
    "print('Test:',gb.score(X_test_100b_pca,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7514792899408284\n",
      "Test: 0.5568627450980392\n",
      "CPU times: user 8.03 s, sys: 6.93 ms, total: 8.04 s\n",
      "Wall time: 8.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gb = GradientBoostingClassifier(n_estimators = 500, learning_rate = 0.01, max_depth= 3, min_samples_leaf=4,\n",
    "                                min_samples_split=4, random_state=42)\n",
    "gb.fit(X_train_100b, y_train)\n",
    "print('Train:', gb.score(X_train_100b,y_train))\n",
    "print('Test:',gb.score(X_test_100b,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
