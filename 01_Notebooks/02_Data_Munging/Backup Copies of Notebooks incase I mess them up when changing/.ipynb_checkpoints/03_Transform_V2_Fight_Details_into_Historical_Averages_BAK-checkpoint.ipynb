{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Transform V2 Fight Details into Historical Averages\n",
    "- Calculate historical average of fight stats for each fight\n",
    "- Everything is from the perspective of the F1 fighter\n",
    "- Stats for the F1 fighter are basically an \"offensive\" rating for the F1 fighter\n",
    "- Stats for the F2 fighter are basically an inverse \"defensive\" rating for the F1 fighter\n",
    "- We also want to look at the difference in the stats for each fight, and then historical average difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in V2_Fight_Details CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_Fight_Fighters_FighterInfo.csv\r\n",
      "V1_Fight_Fighters_FighterInfo_w_flipped.csv\r\n",
      "V2_Fight_Details.csv\r\n",
      "df_ems.csv\r\n",
      "fighter_static_stats.csv\r\n",
      "train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../02_Data/02_Processed_Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../02_Data/02_Processed_Data/V2_Fight_Details.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to add and flip before the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Columns Again\n",
    "F1_Columns = [col for col in df.columns if 'f1' in col.lower()]\n",
    "F2_Columns = [col for col in df.columns if 'f2' in col.lower()]\n",
    "Other_Columns = [col for col in df.columns if not 'f2' in col.lower() and not 'f1' in col.lower()]\n",
    "\n",
    "Ordered_Columns = Other_Columns + F1_Columns + F2_Columns\n",
    "Flipped_Columns = Other_Columns + F2_Columns + F1_Columns\n",
    "\n",
    "# Put Columns in Order\n",
    "df = df[Ordered_Columns]\n",
    "\n",
    "# Create Flipped df\n",
    "flipped_df = df[Flipped_Columns]\n",
    "flipped_df.columns = Ordered_Columns\n",
    "\n",
    "# Concatenate df and flipped_df\n",
    "df = pd.concat([df, flipped_df])\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Column References for Easy Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_Columns = [col for col in df.columns if 'f1' in col.lower()]\n",
    "F2_Columns = [col for col in df.columns if 'f2' in col.lower()]\n",
    "Other_Columns = [col for col in df.columns if not 'f2' in col.lower() and not 'f1' in col.lower()]\n",
    "\n",
    "F1_Strikes = [col for col in F1_Columns if 'strikes' in col.lower()] + ['F1_Knock_Down_Landed']\n",
    "F1_Grappling = [col for col in F1_Columns if 'grappling' in col.lower()]\n",
    "F1_TIP = [col for col in F1_Columns if 'tip' in col.lower()]\n",
    "F1_Identification = ['F1_FighterID','F1_Name'] # This is what its supposed to be incase I add more columns\n",
    "F1_Identification = list(set(F1_Columns) - set(F1_Strikes) - set(F1_Grappling) - set(F1_TIP))\n",
    "\n",
    "F2_Strikes = [col for col in F2_Columns if 'strikes' in col.lower()] + ['F2_Knock_Down_Landed']\n",
    "F2_Grappling = [col for col in F2_Columns if 'grappling' in col.lower()]\n",
    "F2_TIP = [col for col in F2_Columns if 'tip' in col.lower()]\n",
    "F2_Identification = ['F2_FighterID','F2_Name']\n",
    "F2_Identification = list(set(F2_Columns) - set(F2_Strikes) - set(F2_Grappling) - set(F2_TIP))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Transformation:  Calculate success percent for every pair of words that have \"landed\" and \"attempted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perform_calc_success_percent(df):\n",
    "    Both_Landed_Attempts, Attempts_Only, Landed_Only = get_attempts_landed_columns(df)\n",
    "    num_columns_before = df.shape[1]\n",
    "    columns_before = df.columns\n",
    "    print(f'num columns before: {num_columns_before}')\n",
    "    for col in Both_Landed_Attempts:\n",
    "        df = calc_success_percent(df, col)\n",
    "    num_columns_after = df.shape[1]\n",
    "    columns_after = df.columns\n",
    "    print(f\"# Columns Added: {num_columns_after-num_columns_before}\")\n",
    "    print(f'num columns after: {num_columns_after}')\n",
    "    new_columns = list(set(columns_after) - set(columns_before))\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_success_percent(df, col_root):\n",
    "    attempts = col_root + '_attempts'\n",
    "    landed = col_root + '_landed'\n",
    "    success_percent = col_root + '_percent'\n",
    "    \n",
    "    df[success_percent] = df.apply(lambda x: x[landed]/x[attempts] if x[attempts] != 0 else 0, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#calc_success_percent(df, 'F1_Body_Significant_Strikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attempts_landed_columns(df):\n",
    "    list_cols_attempts = []\n",
    "    list_cols_landed = []\n",
    "    for column in df.columns: \n",
    "        if '_attempts' in column.lower():\n",
    "            list_cols_attempts.append(column)\n",
    "        if '_landed' in column.lower():\n",
    "            list_cols_landed.append(column)\n",
    "    list_cols_attempts = [re.sub('_attempts','',col) for col in list_cols_attempts] # Remove \"_Attempts\"\n",
    "    list_cols_landed = [re.sub('_landed','',col) for col in list_cols_landed]\n",
    "    Attempts_Only = set(list_cols_attempts) - set(list_cols_landed)\n",
    "    Landed_Only =  set(list_cols_landed) - set(list_cols_attempts)\n",
    "    Both_Landed_Attempts = set(list_cols_landed) & set(list_cols_attempts)\n",
    "    return Both_Landed_Attempts, Attempts_Only, Landed_Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num columns before: 107\n",
      "# Columns Added: 46\n",
      "num columns after: 153\n"
     ]
    }
   ],
   "source": [
    "df, Landed_Percent = Perform_calc_success_percent(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Transformation:  Calculate In Fight Differentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perform_calc_fight_stat_differential(df):\n",
    "    f1_calc_columns = list(set(F1_Columns) - set(F1_Identification) - set(F1_TIP))\n",
    "    for_calc_columns = [col[3:] for col in f1_calc_columns]\n",
    "    num_columns_before = df.shape[1]\n",
    "    columns_before = df.columns\n",
    "    print(f'num columns before: {num_columns_before}')\n",
    "    for col in for_calc_columns:\n",
    "        df = calc_fight_stat_differential(df, col)\n",
    "    num_columns_after = df.shape[1]\n",
    "    columns_after = df.columns\n",
    "    print(f\"# Columns Added: {num_columns_after-num_columns_before}\")\n",
    "    print(f'num columns after: {num_columns_after}')\n",
    "    new_columns = list(set(columns_after) - set(columns_before))\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fight_stat_differential(df, col_root):\n",
    "    f1 = 'f1_' + col_root\n",
    "    f2 = 'f2_' + col_root\n",
    "    diff = col_root + '_diff'\n",
    "    df[diff] = df.apply(lambda x: (x[f1] - x[f2])/(x[f1] + x[f2]) if (x[f1] + x[f2]) != 0 else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "# calc_fight_stat_differential(df, col_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num columns before: 153\n",
      "# Columns Added: 48\n",
      "num columns after: 201\n"
     ]
    }
   ],
   "source": [
    "df, stat_diff = Perform_calc_fight_stat_differential(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Transformation:  Calculate total TIP and Convert TIP into # ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perform_calc_TIP_in_seconds(df):\n",
    "    tip_columns = [col for col in df.columns if 'tip' in col.lower() and not 'secs' in col.lower()]\n",
    "    num_columns_before = df.shape[1]\n",
    "    columns_before = df.columns\n",
    "    print(f'num columns before: {num_columns_before}')\n",
    "    for col in tip_columns:\n",
    "        df = calc_TIP_in_seconds(df, col)\n",
    "    num_columns_after = df.shape[1]\n",
    "    columns_after = df.columns\n",
    "    print(f\"# Columns Added: {num_columns_after-num_columns_before}\")\n",
    "    print(f'num columns after: {num_columns_after}')\n",
    "    new_columns = list(set(columns_after) - set(columns_before))\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_TIP_in_seconds(df, TIP_column):\n",
    "    TIP_col_sec = TIP_column + '_secs'\n",
    "    df[TIP_col_sec] = df[TIP_column].map(lambda x: calc_one_tip_string_in_seconds(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_one_tip_string_in_seconds(tip_string):\n",
    "    try:\n",
    "        mins, secs = tip_string.split(':')\n",
    "        mins = int(mins)\n",
    "        secs = int(secs)\n",
    "        total_secs = mins*60 + secs\n",
    "        return total_secs\n",
    "    except:\n",
    "        return 0\n",
    "# calc_one_tip_string_in_seconds(tip_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num columns before: 201\n",
      "# Columns Added: 0\n",
      "num columns after: 201\n"
     ]
    }
   ],
   "source": [
    "df, tip_seconds = Perform_calc_TIP_in_seconds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I think I also need to first deal with all missing values before calculating the Expanding Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nulls(df):    \n",
    "    return df.loc[:,df.isnull().sum()!=0].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_nulls(df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Transformation: Calculate Expanding Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First just drop all na to avoid errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4774, 201)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4774, 201)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=1, how='any')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Date from events Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../02_Data/01_Raw_Scraped_Data/Events/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventid</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>644</td>\n",
       "      <td>2013-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701</td>\n",
       "      <td>2015-02-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eventid        date\n",
       "0      644  2013-12-06\n",
       "1      701  2015-02-14"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../02_Data/01_Raw_Scraped_Data/Events/events_df.csv'\n",
    "\n",
    "events_df = pd.read_csv(path, index_col=0)\n",
    "events_df = events_df[['EventId','Date']]\n",
    "events_df = events_df.rename(index=str, columns={\"EventId\": \"eventid\", 'Date':'date'})\n",
    "events_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Date from Events_Df to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(events_df, on='eventid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4774, 202)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../02_Data/02_Processed_Data/V2_Fight_Details_Munged0711.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Mean Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just gets the 'new_df' = filtered for 1 fighter\n",
    "def calculate_expanding_mean(df):\n",
    "    # Find the unique ID for every fighter\n",
    "    unique_ids = df.f1_fighterid.unique()\n",
    "    \n",
    "    cols_to_calc_em = df.select_dtypes(exclude='object').columns\n",
    "    cols_to_calc_em = [col for col in cols_to_calc_em if col not in ['eventid','fightid','currentrnd','maxrnds',\n",
    "                                                                     'f1_fighterid','f2_fighterid']]\n",
    "    \n",
    "    for count, unique_id in enumerate(unique_ids):\n",
    "        new_df = df[(df.f1_fighterid == unique_id)]\n",
    "        if count%50==0:\n",
    "            print(f\"{count} in {len(unique_ids)}\")\n",
    "        \n",
    "        \n",
    "        # Calculate Expanding Mean\n",
    "        df_stub = new_df.sort_values('date')[['eventid','fightid', 'f1_fighterid', 'date']].copy()\n",
    "        df_em_part = new_df.sort_values('date').expanding().mean().shift()[cols_to_calc_em]\n",
    "        df_em_part.columns = [col + '_em' for col in df_em_part.columns]\n",
    "        df_em = pd.concat([df_stub,df_em_part], axis=1).copy()        \n",
    "        df_em = df_em.iloc[1:, :]\n",
    "        \n",
    "        try:\n",
    "            df_ems = pd.concat([df_ems, df_em], axis=0)\n",
    "\n",
    "        except NameError:\n",
    "            df_ems = df_em.copy()\n",
    "        \n",
    "        \n",
    "    return df_ems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 in 1091\n",
      "50 in 1091\n",
      "100 in 1091\n",
      "150 in 1091\n",
      "200 in 1091\n",
      "250 in 1091\n",
      "300 in 1091\n",
      "350 in 1091\n",
      "400 in 1091\n",
      "450 in 1091\n",
      "500 in 1091\n",
      "550 in 1091\n",
      "600 in 1091\n",
      "650 in 1091\n",
      "700 in 1091\n",
      "750 in 1091\n",
      "800 in 1091\n",
      "850 in 1091\n",
      "900 in 1091\n",
      "950 in 1091\n",
      "1000 in 1091\n",
      "1050 in 1091\n"
     ]
    }
   ],
   "source": [
    "df_ems = calculate_expanding_mean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3683, 196)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ems.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the df_ems data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_Fight_Fighters_FighterInfo.csv\r\n",
      "V1_Fight_Fighters_FighterInfo_w_flipped.csv\r\n",
      "V2_Fight_Details.csv\r\n",
      "df_ems.csv\r\n",
      "train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../02_Data/02_Processed_Data/df_ems.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ems.to_csv('../../02_Data/02_Processed_Data/df_ems.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We should be ready to create the actual training data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1_df = pd.read_csv('../../02_Data/02_Processed_Data/V1_Fight_Fighters_FighterInfo_w_flipped.csv', index_col=0)\n",
    "V1_df.columns = [col.lower() for col in V1_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventid</th>\n",
       "      <th>fightid</th>\n",
       "      <th>method</th>\n",
       "      <th>possiblerds</th>\n",
       "      <th>endingroundnum</th>\n",
       "      <th>f1_fullname</th>\n",
       "      <th>f2_fullname</th>\n",
       "      <th>f1_outcome</th>\n",
       "      <th>f2_outcome</th>\n",
       "      <th>f1_born_city</th>\n",
       "      <th>...</th>\n",
       "      <th>f2_fights_out_city</th>\n",
       "      <th>f2_fights_out_country</th>\n",
       "      <th>f2_fights_out_state</th>\n",
       "      <th>f2_height</th>\n",
       "      <th>f2_loss</th>\n",
       "      <th>f2_nc</th>\n",
       "      <th>f2_stance</th>\n",
       "      <th>f2_totfights</th>\n",
       "      <th>f2_weight</th>\n",
       "      <th>f2_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>644</td>\n",
       "      <td>4512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Antonio Silva</td>\n",
       "      <td>Mark Hunt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brasilia</td>\n",
       "      <td>...</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>18</td>\n",
       "      <td>265</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>644</td>\n",
       "      <td>4468</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>James Te-Huna</td>\n",
       "      <td>Mauricio Rua</td>\n",
       "      <td>Loss</td>\n",
       "      <td>Win</td>\n",
       "      <td>Darfield</td>\n",
       "      <td>...</td>\n",
       "      <td>Curitiba</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Parana</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>30</td>\n",
       "      <td>205</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   eventid  fightid  method  possiblerds  endingroundnum    f1_fullname  \\\n",
       "0      644     4512     NaN            5             5.0  Antonio Silva   \n",
       "1      644     4468  KO/TKO            3             1.0  James Te-Huna   \n",
       "\n",
       "    f2_fullname f1_outcome f2_outcome f1_born_city   ...   f2_fights_out_city  \\\n",
       "0     Mark Hunt        NaN        NaN     Brasilia   ...             Auckland   \n",
       "1  Mauricio Rua       Loss        Win     Darfield   ...             Curitiba   \n",
       "\n",
       "  f2_fights_out_country f2_fights_out_state f2_height  f2_loss  f2_nc  \\\n",
       "0           New Zealand                 NaN        70        8      0   \n",
       "1                Brazil              Parana        73        8      0   \n",
       "\n",
       "  f2_stance f2_totfights f2_weight  f2_win  \n",
       "0  Orthodox           18       265       9  \n",
       "1  Orthodox           30       205      22  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V1_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the entire EM dataset to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventid</th>\n",
       "      <th>fightid</th>\n",
       "      <th>f1_fighterid</th>\n",
       "      <th>date</th>\n",
       "      <th>f1_body_significant_strikes_attempts_em</th>\n",
       "      <th>f1_body_significant_strikes_landed_em</th>\n",
       "      <th>f1_body_total_strikes_attempts_em</th>\n",
       "      <th>f1_body_total_strikes_landed_em</th>\n",
       "      <th>f1_clinch_body_strikes_attempts_em</th>\n",
       "      <th>f1_clinch_body_strikes_landed_em</th>\n",
       "      <th>...</th>\n",
       "      <th>distance_leg_strikes_attempts_diff_em</th>\n",
       "      <th>distance_body_strikes_landed_diff_em</th>\n",
       "      <th>clinch_body_strikes_attempts_diff_em</th>\n",
       "      <th>grappling_takedowns_landed_diff_em</th>\n",
       "      <th>head_significant_strikes_attempts_diff_em</th>\n",
       "      <th>legs_total_strikes_attempts_diff_em</th>\n",
       "      <th>body_significant_strikes_landed_diff_em</th>\n",
       "      <th>ground_leg_strikes_attempts_diff_em</th>\n",
       "      <th>distance_body_strikes_attempts_diff_em</th>\n",
       "      <th>head_significant_strikes_landed_diff_em</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>688</td>\n",
       "      <td>5016</td>\n",
       "      <td>2239</td>\n",
       "      <td>2014-10-04</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.290323</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704</td>\n",
       "      <td>5268</td>\n",
       "      <td>2239</td>\n",
       "      <td>2015-03-14</td>\n",
       "      <td>20.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>-0.014286</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.276190</td>\n",
       "      <td>0.259601</td>\n",
       "      <td>0.095685</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>-0.516364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      eventid  fightid  f1_fighterid        date  \\\n",
       "3397      688     5016          2239  2014-10-04   \n",
       "0         704     5268          2239  2015-03-14   \n",
       "\n",
       "      f1_body_significant_strikes_attempts_em  \\\n",
       "3397                                     30.0   \n",
       "0                                        20.5   \n",
       "\n",
       "      f1_body_significant_strikes_landed_em  \\\n",
       "3397                                   26.0   \n",
       "0                                      16.0   \n",
       "\n",
       "      f1_body_total_strikes_attempts_em  f1_body_total_strikes_landed_em  \\\n",
       "3397                               86.0                             82.0   \n",
       "0                                  67.5                             63.0   \n",
       "\n",
       "      f1_clinch_body_strikes_attempts_em  f1_clinch_body_strikes_landed_em  \\\n",
       "3397                                22.0                              19.0   \n",
       "0                                   13.5                              11.0   \n",
       "\n",
       "                       ...                     \\\n",
       "3397                   ...                      \n",
       "0                      ...                      \n",
       "\n",
       "      distance_leg_strikes_attempts_diff_em  \\\n",
       "3397                               0.250000   \n",
       "0                                  0.569444   \n",
       "\n",
       "      distance_body_strikes_landed_diff_em  \\\n",
       "3397                              0.400000   \n",
       "0                                -0.014286   \n",
       "\n",
       "      clinch_body_strikes_attempts_diff_em  \\\n",
       "3397                              0.466667   \n",
       "0                                 0.447619   \n",
       "\n",
       "      grappling_takedowns_landed_diff_em  \\\n",
       "3397                           -1.000000   \n",
       "0                              -0.666667   \n",
       "\n",
       "      head_significant_strikes_attempts_diff_em  \\\n",
       "3397                                  -0.285714   \n",
       "0                                     -0.276190   \n",
       "\n",
       "      legs_total_strikes_attempts_diff_em  \\\n",
       "3397                            -0.290323   \n",
       "0                                0.259601   \n",
       "\n",
       "      body_significant_strikes_landed_diff_em  \\\n",
       "3397                                 0.268293   \n",
       "0                                    0.095685   \n",
       "\n",
       "      ground_leg_strikes_attempts_diff_em  \\\n",
       "3397                                  0.0   \n",
       "0                                     0.5   \n",
       "\n",
       "      distance_body_strikes_attempts_diff_em  \\\n",
       "3397                                0.333333   \n",
       "0                                   0.121212   \n",
       "\n",
       "      head_significant_strikes_landed_diff_em  \n",
       "3397                                -0.272727  \n",
       "0                                   -0.516364  \n",
       "\n",
       "[2 rows x 196 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ems.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eventid',\n",
       " 'fightid',\n",
       " 'f1_fullname',\n",
       " 'f2_fullname',\n",
       " 'f1_fighterid',\n",
       " 'f2_fighterid',\n",
       " 'f1_outcome']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = ['EventID','FightID','F1_FullName','F2_FullName','F1_FighterID','F2_FighterID', 'F1_Outcome']\n",
    "\n",
    "[col.lower() for col in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ems_f1.eventid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Stub Data\n",
    "train_stub = ['eventid','fightid','f1_fullname','f2_fullname','f1_fighterid','f2_fighterid','f1_outcome']\n",
    "train = V1_df[train_stub].reset_index().drop(columns='index')\n",
    "\n",
    "\n",
    "df_ems_f1 = df_ems.copy()\n",
    "\n",
    "# First append 'F1_' for all fighter 1 data\n",
    "df_ems_f1.columns = ['eventid','fightid','f1_fighterid','date'] + \\\n",
    "                    ['f1_' + col for col in df_ems_f1.columns if col not in \\\n",
    "                    ['eventid','fightid','f1_fighterid','date']]\n",
    "\n",
    "# Merge F1 Expanding Means\n",
    "train = train.merge(df_ems_f1, left_on=['eventid','fightid','f1_fighterid'],\n",
    "                    right_on=['eventid','fightid','f1_fighterid'])\n",
    "\n",
    "#Setup \n",
    "df_ems_f2 = df_ems.drop(columns=['date']).copy()\n",
    "df_ems_f2.columns = ['eventid','fightid','f2_fighterid'] + \\\n",
    "                    ['f2_' + col for col in df_ems_f2.columns if col not in \\\n",
    "                    ['eventid','fightid','f1_fighterid']]\n",
    "\n",
    "# Merge em for fighter 2\n",
    "train = train.merge(df_ems_f2, left_on=['eventid','fightid','f2_fighterid'], \n",
    "                    right_on=['eventid','fightid','f2_fighterid'])\n",
    "\n",
    "# drop columns w/o outcome\n",
    "train = train.dropna(axis=0, how='any')\n",
    "\n",
    "# Check empty columns:\n",
    "check_nulls(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to clean up data a bit more before I can model\n",
    "- Label from win/loss to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Win     1590\n",
       "Loss    1590\n",
       "Name: f1_outcome, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.f1_outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['outcome'] = train.f1_outcome.map(lambda x: 1 if x=='Win' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Train dataset for some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../../02_Data/02_Processed_Data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the data is \"prepped\" and I can try to train test split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = set(train.f1_fighterid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = list(set(train.f1_fighterid))\n",
    "test_full = train[0:0]\n",
    "train_full = train[0:0]\n",
    "\n",
    "\n",
    "for fighter_id in unique_ids:\n",
    "    sub_df = train[train.f1_fighterid == fighter_id].sort_values('date', ascending=False)\n",
    "#     print(sub_df.shape[0])\n",
    "#     print(fighter_id)\n",
    "    if sub_df.shape[0] > 6:\n",
    "        test_records = sub_df[:2]\n",
    "        train_records = sub_df[2:]\n",
    "        test_full = pd.concat([test_full, test_records], axis=0)\n",
    "        train_full = pd.concat([train_full, train_records], axis=0)\n",
    "    elif sub_df.shape[0] > 3:\n",
    "        test_records = sub_df[:1]\n",
    "        train_records = sub_df[1:]\n",
    "        test_full = pd.concat([test_full, test_records], axis=0)\n",
    "        train_full = pd.concat([train_full, train_records], axis=0)\n",
    "    else:\n",
    "        train_records = sub_df\n",
    "        train_full = pd.concat([train_full, train_records], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18745332337565349"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(test_full)/len(train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split out X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'outcome'\n",
    "features = [col for col in train_full.columns if col != label]\n",
    "y_train = train_full[label]\n",
    "X_train = train_full[features]\n",
    "\n",
    "# Drop non-number features\n",
    "X_train = X_train.select_dtypes(exclude='object')\n",
    "# Drop non-feature columns\n",
    "X_train = X_train.drop(columns=['eventid','fightid','f1_fighterid','f2_fighterid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2678, 384)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'outcome'\n",
    "features = [col for col in test_full.columns if col != label]\n",
    "y_test = test_full[label]\n",
    "X_test = test_full[features]\n",
    "\n",
    "# Drop non-number features\n",
    "X_test = X_test.select_dtypes(exclude='object')\n",
    "# Drop non-feature columns\n",
    "X_test = X_test.drop(columns=['eventid','fightid','f1_fighterid','f2_fighterid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build a quick and dirty model and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6631814787154593\n",
      "Test: 0.5677290836653387\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('Train:', lr.score(X_train,y_train))\n",
    "print('Test:', lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9873039581777446\n",
      "Test: 0.547808764940239\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "print('Train:', rf.score(X_train,y_train))\n",
    "print('Test:',rf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.5418222554144885\n",
      "Best Parameters: {}\n",
      "Test: 0.5597609561752988\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(random_state=42)\n",
    "ada_params = {}\n",
    "gs = GridSearchCV(ada, param_grid=ada_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best Score:', gs.best_score_)\n",
    "print('Best Parameters:', gs.best_params_)\n",
    "print('Test:',gs.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] learning_rate=0.05, max_depth=3 .................................\n",
      "[CV] learning_rate=0.05, max_depth=3 .................................\n",
      "[CV] learning_rate=0.05, max_depth=3 .................................\n",
      "[CV] .................. learning_rate=0.05, max_depth=3, total=   3.0s\n",
      "[CV] learning_rate=0.05, max_depth=4 .................................\n",
      "[CV] .................. learning_rate=0.05, max_depth=3, total=   3.1s\n",
      "[CV] learning_rate=0.05, max_depth=4 .................................\n",
      "[CV] .................. learning_rate=0.05, max_depth=3, total=   3.2s\n",
      "[CV] learning_rate=0.05, max_depth=4 .................................\n",
      "[CV] .................. learning_rate=0.05, max_depth=4, total=   4.7s\n",
      "[CV] learning_rate=0.05, max_depth=5 .................................\n",
      "[CV] .................. learning_rate=0.05, max_depth=4, total=   4.6s\n",
      "[CV] learning_rate=0.05, max_depth=5 .................................\n",
      "[CV] .................. learning_rate=0.05, max_depth=4, total=   4.8s\n",
      "[CV] learning_rate=0.05, max_depth=5 .................................\n",
      "[CV] .................. learning_rate=0.05, max_depth=5, total=   6.7s\n",
      "[CV] learning_rate=0.1, max_depth=3 ..................................\n",
      "[CV] .................. learning_rate=0.05, max_depth=5, total=   6.6s\n",
      "[CV] learning_rate=0.1, max_depth=3 ..................................\n",
      "[CV] .................. learning_rate=0.05, max_depth=5, total=   6.8s\n",
      "[CV] learning_rate=0.1, max_depth=3 ..................................\n",
      "[CV] ................... learning_rate=0.1, max_depth=3, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=4 ..................................\n",
      "[CV] ................... learning_rate=0.1, max_depth=3, total=   3.0s\n",
      "[CV] learning_rate=0.1, max_depth=4 ..................................\n",
      "[CV] ................... learning_rate=0.1, max_depth=3, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=4 ..................................\n",
      "[CV] ................... learning_rate=0.1, max_depth=4, total=   4.5s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ................... learning_rate=0.1, max_depth=4, total=   4.5s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ................... learning_rate=0.1, max_depth=4, total=   4.7s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ................... learning_rate=0.1, max_depth=5, total=   6.6s\n",
      "[CV] learning_rate=0.3, max_depth=3 ..................................\n",
      "[CV] ................... learning_rate=0.1, max_depth=5, total=   6.7s\n",
      "[CV] learning_rate=0.3, max_depth=3 ..................................\n",
      "[CV] ................... learning_rate=0.1, max_depth=5, total=   6.7s\n",
      "[CV] learning_rate=0.3, max_depth=3 ..................................\n",
      "[CV] ................... learning_rate=0.3, max_depth=3, total=   3.1s\n",
      "[CV] learning_rate=0.3, max_depth=4 ..................................\n",
      "[CV] ................... learning_rate=0.3, max_depth=3, total=   3.1s\n",
      "[CV] learning_rate=0.3, max_depth=4 ..................................\n",
      "[CV] ................... learning_rate=0.3, max_depth=3, total=   3.0s\n",
      "[CV] learning_rate=0.3, max_depth=4 ..................................\n",
      "[CV] ................... learning_rate=0.3, max_depth=4, total=   4.7s\n",
      "[CV] learning_rate=0.3, max_depth=5 ..................................\n",
      "[CV] ................... learning_rate=0.3, max_depth=4, total=   4.6s\n",
      "[CV] learning_rate=0.3, max_depth=5 ..................................\n",
      "[CV] ................... learning_rate=0.3, max_depth=4, total=   4.7s\n",
      "[CV] learning_rate=0.3, max_depth=5 ..................................\n",
      "[CV] ................... learning_rate=0.3, max_depth=5, total=   6.6s\n",
      "[CV] ................... learning_rate=0.3, max_depth=5, total=   6.5s\n",
      "[CV] ................... learning_rate=0.3, max_depth=5, total=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  27 out of  27 | elapsed:   43.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.1 s, sys: 99.8 ms, total: 7.2 s\n",
      "Wall time: 50.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb_params = {\n",
    "    'learning_rate': [0.05, 0.1, 0.3],\n",
    "    'max_depth': [3,4,5]\n",
    "}\n",
    "gb_gs = GridSearchCV(gb, param_grid=gb_params, verbose=2, n_jobs=3 )\n",
    "gb_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'learning_rate': 0.05, 'max_depth': 4}\n",
      "Train: 0.9213528932355338\n",
      "Test: 0.5772727272727273\n"
     ]
    }
   ],
   "source": [
    "print('Best Params:', gb_gs.best_params_)\n",
    "print('Train:', gb_gs.score(X_train,y_train))\n",
    "print('Test:', gb_gs.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] learning_rate=0.5, n_estimators=50 ..............................\n",
      "[CV] learning_rate=0.5, n_estimators=50 ..............................\n",
      "[CV] learning_rate=0.5, n_estimators=50 ..............................\n",
      "[CV] ............... learning_rate=0.5, n_estimators=50, total=   2.1s\n",
      "[CV] ............... learning_rate=0.5, n_estimators=50, total=   2.1s\n",
      "[CV] learning_rate=0.5, n_estimators=100 .............................\n",
      "[CV] ............... learning_rate=0.5, n_estimators=50, total=   2.1s\n",
      "[CV] learning_rate=0.5, n_estimators=100 .............................\n",
      "[CV] learning_rate=0.5, n_estimators=100 .............................\n",
      "[CV] .............. learning_rate=0.5, n_estimators=100, total=   4.2s\n",
      "[CV] learning_rate=1.0, n_estimators=50 ..............................\n",
      "[CV] .............. learning_rate=0.5, n_estimators=100, total=   4.3s\n",
      "[CV] learning_rate=1.0, n_estimators=50 ..............................\n",
      "[CV] .............. learning_rate=0.5, n_estimators=100, total=   4.3s\n",
      "[CV] learning_rate=1.0, n_estimators=50 ..............................\n",
      "[CV] ............... learning_rate=1.0, n_estimators=50, total=   2.1s\n",
      "[CV] learning_rate=1.0, n_estimators=100 .............................\n",
      "[CV] ............... learning_rate=1.0, n_estimators=50, total=   2.1s\n",
      "[CV] ............... learning_rate=1.0, n_estimators=50, total=   2.1s\n",
      "[CV] learning_rate=1.0, n_estimators=100 .............................\n",
      "[CV] learning_rate=1.0, n_estimators=100 .............................\n",
      "[CV] .............. learning_rate=1.0, n_estimators=100, total=   4.2s\n",
      "[CV] .............. learning_rate=1.0, n_estimators=100, total=   4.2s\n",
      "[CV] .............. learning_rate=1.0, n_estimators=100, total=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  12 out of  12 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.31 s, sys: 67.1 ms, total: 3.38 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators':[50,100],\n",
    "    'learning_rate': [0.5, 1.0]\n",
    "}\n",
    "ada_gs = GridSearchCV(ada, param_grid=ada_params, verbose=2, n_jobs=3)\n",
    "ada_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.5418222554144885\n",
      "Best Parameters: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "Train: 0.6747572815533981\n",
      "Test: 0.5597609561752988\n"
     ]
    }
   ],
   "source": [
    "print('Best Score:', ada_gs.best_score_)\n",
    "print('Best Parameters:', ada_gs.best_params_)\n",
    "print('Train:',ada_gs.score(X_train,y_train))\n",
    "print('Test:',ada_gs.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
